{"meta":{"title":"liuhui | 刘辉","subtitle":"不忘初心","description":"北京林业大学在读硕士<br>liuhui@bjfu.edu.cn","author":"Hui Liu","url":"https://hui-liu.github.io"},"pages":[{"title":"about","date":"2017-03-02T14:28:37.000Z","updated":"2017-03-02T14:29:40.214Z","comments":true,"path":"about/index.html","permalink":"https://hui-liu.github.io/about/index.html","excerpt":"","text":"关于我北京林业大学在读硕士 liuhui@bjfu.edu.cn"},{"title":"categories","date":"2017-03-02T14:34:26.000Z","updated":"2017-03-02T14:34:54.101Z","comments":true,"path":"categories/index.html","permalink":"https://hui-liu.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-03-02T14:31:33.000Z","updated":"2017-03-02T14:32:50.317Z","comments":true,"path":"tags/index.html","permalink":"https://hui-liu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"networkx 笔记","slug":"networkx-笔记","date":"2017-03-15T14:12:24.000Z","updated":"2017-03-15T14:45:11.346Z","comments":true,"path":"2017-03-15-networkx-笔记.html","link":"","permalink":"https://hui-liu.github.io/2017-03-15-networkx-笔记.html","excerpt":"","text":"NetworkX 复杂网络分析笔记主要参考1，2，3。 数据 facebook_combined.csv，relation_weight_sam.csv。 1. 建图networkx可以建立简单无向图graph，有向图digraph，可重复边的multi-graph。 1.1 简单无向图 graphimport networkx as nx#建立一个空的无向图GG=nx.Graph()#添加一个节点1G.add_node(1)#添加一条边2-3（隐含着添加了两个节点2、3）G.add_edge(2,3)#对于无向图，边3-2与边2-3被认为是一条边G.add_edge(3,2)#输出全部的节点： [1, 2, 3]print G.nodes()#输出全部的边：[(2, 3)]print G.edges()#输出边的数量：1print G.number_of_edges()#输出点数print g.number_of_nodes() 1.2 有向图 digraph有向图的建立方式和无向图基本类似，只是在上述代码的第二行，将G = nx.Graph() 改为 G = nx.DiGraph() 。需要注意的是，此时再添加边3-2与边2-3，则被认为是两条不同的 import networkx as nxD=nx.DiGraph() 同时，有向图和无向图是可以相互转化的，分别用到Graph.to_undirected() 和 Graph.to_directed()两个方法。 1.3 加权图有向图和无向图都可以给边赋予权重，用到的方法是add_weighted_edges_from，它接受1个或多个三元组[u,v,w]作为参数，其中u是起点，v是终点，w是权重。例如： # 添加0-1、1-2和2-3三条边，权重分别是3.0和7.5G.add_weighted_edges_from([(0,1,3.0),(1,2,7.5),(2,3,1.0)])# 如果想读取权重，可以使用get_edge_data方法，它接受两个参数u和v，即边的起始点。print G.get_edge_data(1,2)# 选出边的权重超过一个阈值的边estrong = [(u,v) for (u,v,d) in G.edges(data=True) if d[\"weight\"] &gt; 3.0]print estrong # [(1, 2)] 这是一个加权图的代码 from matplotlib import useuse(\"Agg\")import matplotlib.pyplot as pltimport networkx as nximport pandas as pddf = pd.read_csv(\"../data/relation_weight_sam.csv\")G = nx.from_pandas_dataframe(df, 'node1', 'node2', edge_attr='weight' )# saves the positions of the nodes on the visualization# In detail positions is a dictionary where each node is# a key and the value is a position on the graph# &#123;'Fam38a_predicted': array([ 0.52246857, 0.4412573 ], dtype=float32),...&#125;positions = nx.spring_layout(G)# pass positions and set hold=Truenx.draw(G, pos=positions, hold=True, with_labels=False, node_size=30)weights = [w[2]['weight']*5 for w in G.edges(data=True)]#width can be array of floatsnx.draw_networkx_edges(G, pos=positions, width=weights)plt.savefig(\"../output/net_weight.png\")# 前十行数据，weight是通过\"numpy.random.rand()\"模拟的。\"\"\"node1 node2 weightAblim2 Acsl6 0.0656480910603Ablim2 Apeg1 0.0727940253706Ablim2 Atp2a2 0.5280955211Ablim2 Boll_predicted 0.200347948345Ablim2 Cap2 0.108700562945Ablim2 Copb1 0.546335670525Ablim2 Creld2 0.420412397031Ablim2 Dtna_predicted 0.24546480993Ablim2 Dusp8_predicted 0.932345236242\"\"\" 1.4 可重复边的 multi-graphimport networkx as nxM=nx.MultiGraph() 1.5 点这里的点可以是任意可区分的对象（hashable），比如数字，字符串，对象等。 G.add_node(1)G.add_node('first_node')#这里用一个对象多为key来唯一区别一个点#我们还能够用一个列表来批量加入点G.add_nodes_from([1,2,3])#还可以用一个图对象作为点，嵌入到其他图中G.add_node(D) #这里D作为一个点的key#或者把一个图的所有点赋予另一个图G.add_nodes_from(D) #这里返回D的所有点，赋予G#与加入相同的传递方法，我们也可以删除点G.remove_node(1)G.remove_nodes_from([1,2,3]) 1.6 边这里的边可以使用两个单独的对象作为输入 G.add_edge(1,2) #表示1，2之间有一条边。#如果不存在点1，2，则会自动加入点集合。#或者以元组的形式作为输入e=(1,2)G.add_edge(*e)#这里的*代表吧元组解包（unpack），当作一个个的值扔到函数中去。#如果不解包，等价于#G.add_edge(e)=G.add_edge((1,2))与参数传递的方式不符。#类似的，我们还可以使用包含元组的列表来传递参数G.add_edges_from([(1,2),(2,3)])#我们还可以报一个图的边赋予另一个图G.add_edges_from(H)#删除G.remove_edge(1,2)G.remove_edges_from([(1,2),(2,3)]) 1.7 访问node_list = G.nodes()edge_list = G.edges()#可以返回包含点与边的列表node = G.node[‘first_node’]#如上根据key返回点edge = G.edge['first_node']['second_node']#同样的方法，返回两个key之间的边 1.8 属性我们可以给图，点，边赋予各种属性，最简单的就是权值属性 G.add_node(1,time='5pm')#在添加时跟上属性G.add_nodes_from([1,2,3],time='5pm')#批量添加点是，跟上统一的属性G.add_nodes_from([(3,&#123;'time':'5pm'&#125;), (4,&#123;'time':'4pm'&#125;)])#或者写成元组列表[（key,dict），（key,dict）]的形式G.node[1]['time']#根据字典key访问属性值。#给边添加属性也类似G.add_edge(1,2,time='3am')G.add_edges_from([(1,2,&#123;'time'='5pm'&#125;),(2,3,&#123;'time'=3am&#125;)])#批量赋予属性G.edge[1][2][‘time’]#访问#我们还可以使用特定的函数批量返回属性，如time = nx.get_edge_attributes(G,'time')#返回得到以元组为key,time属性为值得一个字典time[(1,2)] 1.9 图算法NetworkX提供了常用的图论经典算法，例如DFS、BFS、最短路、最小生成树、最大流等等，非常丰富，如果不做复杂网络，只作图论方面的工作，也可以应用NetworkX作为基本的开发包。 #调用多源最短路径算法，计算图G所有节点间的最短路径path=nx.all_pairs_shortest_path(G)#输出节点0、2之间的最短路径序列： [0, 1, 2]print path[0][2] 1.10 画图nx.draw(G) # 方法，至少接受一个参数：待绘制的网络G matplotlib.show() #显示出来 画图参数运行样式 node_size: 指定节点的尺寸大小(默认是300) node_color: 指定节点的颜色 (默认是红色，可以用字符串简单标识颜色，例如’r’为红色，’b’为绿色等) node_shape: 节点的形状（默认是圆形，用字符串’o’标识） alpha: 透明度 (默认是1.0，不透明，0为完全透明) width: 边的宽度 (默认为1.0) edge_color: 边的颜色(默认为黑色) style: 边的样式(默认为实现，可选： solid|dashed|dotted,dashdot) with_labels: 节点是否带标签（默认为True） font_size: 节点标签字体大小 (默认为12) font_color: 节点标签字体颜色（默认为黑色） 运用布局 circular_layout：节点在一个圆环上均匀分布 random_layout：节点随机分布 shell_layout：节点在同心圆上分布 spring_layout： 用Fruchterman-Reingold算法排列节点（样子类似多中心放射状） spectral_layout：根据图的拉普拉斯特征向量排列节点 添加文本 用plt.title()方法可以为图形添加一个标题，该方法接受一个字符串作为参数。 fontsize参数用来指定标题的大小。例如：plt.title(“BA Networks”, fontsize = 20)。 如果要在任意位置添加文本，则可以采用plt.text()方法。 2. 四种网络模型NetworkX提供了4种常见网络的建模方法，分别是：规则图，ER随机图，WS小世界网络和BA无标度网络。 2.1 规则图规则图差不多是最没有复杂性的一类图，random_graphs.random_regular_graph(d, n)方法可以生成一个含有n个节点，每个节点有d个邻居节点的规则图。 下面一段示例代码，生成了包含20个节点、每个节点有3个邻居的规则图： import networkx as nximport matplotlib.pyplot as plt# regular graphy# generate a regular graph which has 20 nodes &amp; each node has 3 neghbour nodes.RG = nx.random_graphs.random_regular_graph(3, 20)# the spectral layoutpos = nx.spectral_layout(RG)# draw the regular graphynx.draw(RG, pos, with_labels = False, node_size = 30)plt.show() 2.2 ER随机图ER随机图是早期研究得比较多的一类“复杂”网络，模型的基本思想是以概率p连接N个节点中的每一对节点。用random_graphs.erdos_renyi_graph(n,p)方法生成一个含有n个节点、以概率p连接的ER随机图： import networkx as nximport matplotlib.pyplot as plt# erdos renyi graph# generate a graph which has n=20 nodes, probablity p = 0.2.ER = nx.random_graphs.erdos_renyi_graph(20, 0.2)# the shell layoutpos = nx.shell_layout(ER)nx.draw(ER, pos, with_labels = False, node_size = 30)plt.show() 2.3 WS小世界网络 用random_graphs.watts_strogatz_graph(n, k, p)方法生成一个含有n个节点、每个节点有k个邻居、以概率p随机化重连边的WS小世界网络。 下面是一个例子： networkx-笔记/import networkx as nximport matplotlib.pyplot as plt# WS network# generate a WS network which has 20 nodes,# each node has 4 neighbour nodes,# random reconnection probability was 0.3.WS = nx.random_graphs.watts_strogatz_graph(20, 4, 0.3)# circular layoutpos = nx.circular_layout(WS)nx.draw(WS, pos, with_labels = False, node_size = 30)plt.show() 2.4 BA无标度网络用random_graphs.barabasi_albert_graph(n, m)方法生成一个含有n个节点、每次加入m条边的BA无标度网络。 下面是一个例子： import networkx as nximport matplotlib.pyplot as plt# BA scale-free degree network# generalize BA network which has 20 nodes, m = 1BA = nx.random_graphs.barabasi_albert_graph(20, 1)# spring layoutpos = nx.spring_layout(BA)nx.draw(BA, pos, with_labels = False, node_size = 30)plt.show() 对BA模型实现代码的分析 #定义一个方法，它有两个参数：n - 网络节点数量；m - 每步演化加入的边数量def barabasi_albert_graph(n, m): # 生成一个包含m个节点的空图 (即BA模型中t=0时的m0个节点) G=empty_graph(m) # 定义新加入边要连接的m个目标节点 targets=range(m) # 将现有节点按正比于其度的次数加入到一个数组中，初始化时的m个节点度均为0，所以数组为空 repeated_nodes=[] # 添加其余的 n-m 个节点，第一个节点编号为m（Python的数组编号从0开始） source=m # 循环添加节点 while source&lt;n: # 从源节点连接m条边到选定的m个节点targets上（注意targets是上一步生成的） G.add_edges_from(zip([source]*m,targets)) # 对于每个被选择的节点，将它们加入到repeated_nodes数组中（它们的度增加了1） repeated_nodes.extend(targets) # 将源点m次加入到repeated_nodes数组中（它的度增加了m） repeated_nodes.extend([source]*m) # 从现有节点中选取m个节点 ，按正比于度的概率（即度优先连接） targets=set() while len(targets)&lt;m: #按正比于度的概率随机选择一个节点，见注释1 x=random.choice(repeated_nodes) #将其添加到目标节点数组targets中 targets.add(x) #挑选下一个源点，转到循环开始，直到达到给定的节点数n source += 1 #返回所得的图G return G from matplotlib import useuse(\"Agg\")import randomimport networkx as nxfrom networkx.generators.classic import empty_graphimport matplotlib.pyplot as pltdef barabasi_albert_graph(n, m): G=empty_graph(m) targets=range(m) repeated_nodes=[] source=m while source&lt;n: G.add_edges_from(zip([source]*m,targets)) repeated_nodes.extend(targets) repeated_nodes.extend([source]*m) targets=set() while len(targets)&lt;m: x=random.choice(repeated_nodes) targets.add(x) source += 1 return G ##G=nx.Graph()G = barabasi_albert_graph(400,6)pos = nx.spring_layout(G)nx.draw(G, pos, with_labels = False, node_size = 30)plt.savefig(\"../output/BA_400_6.png\") 3. 统计指标计算3.1 度、度分布 NetworkX可以用来统计图中每个节点的度，并生成度分布序列。 import networkx as nximport matplotlib.pyplot as plt #生成一个n=1000，m=3的BA无标度网络G = nx.random_graphs.barabasi_albert_graph(1000,3)#返回某个节点的度print G.degree(0)#返回所有节点的度print G.degree()#返回图中所有节点的度分布序列（从1至最大度的出现频次）print nx.degree_histogram(G)#返回图中所有节点的度分布序列degree = nx.degree_histogram(G)#生成x轴序列，从1到最大度x = range(len(degree))#将频次转换为频率y = [z / float(sum(degree)) for z in degree]#在双对数坐标轴上绘制度分布曲线plt.loglog(x,y,color=\"blue\",linewidth=2)#显示图表plt.show() 3.2 群聚系数# 平均群聚系数nx.average_clustering(G)# 各个节点的群聚系数nx.clustering(G) 3.3 直径和平均距离# 图G的直径（最长最短路径的长度）nx.diameter(G)# 图G所有节点间平均最短路径长度nx.average_shortest_path_length(G) 3.4 中心性一个图的直径是所有点之间最长的最短路径。在连接中心度，我们需要寻找一个点，这个点出现在很多点的最短路径中。出现的次数越多，连接中心性越高。这样的点，可以作为一个桥梁作用。意义：分析该节点对网络信息流动的影响，如：考察此人的社交能力或对于社会网络中信息流动的影响力。 betweenness centralityimport networkx as nximport matplotlib.pyplot as pltG=nx.Graph()print G.edges() # []G.add_edges_from([(1,2),(2,3),(2,4),(2,5),(1,3),(1,4),(3,5),(4,6)])print G.edges()#[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (2, 5), (3, 5), (4, 6)]# betweenness centralitybc = nx.betweenness_centrality(G)print sorted(bc.items(), key=lambda k: k[1], reverse=True)# [(4, 0.4), (2, 0.35000000000000003), (1, 0.1), (3, 0.05), (5, 0.0), (6, 0.0)]# spring layoutpos = nx.spring_layout(G)nx.draw(G, pos, with_labels = True, node_size = 100,font_size=6,font_color='b')plt.show() 另一个复杂的例子 import networkx as nximport matplotlib.pyplot as pltimport communityimport pandas as pdimport sys# Exploratory Data Analysis# datadf = pd.read_csv(sys.argv[1])#node1 = list(df[\"node1\"])G = nx.from_pandas_dataframe(df, 'node1', 'node2', #edge_attr='weight', #create_using=nx.MultiGraph() )#Quick snapshot of the Networkprint nx.info(G)#Create network layout for visualizationsspring_pos = nx.spring_layout(G)plt.axis(\"off\")def most_important(G): \"\"\" returns a copy of G with the most important nodes according to the pagerank \"\"\" ranking = nx.betweenness_centrality(G).items() #print ranking r = [x[1] for x in ranking] m = sum(r)/len(r) # mean centrality t = m*10 # threshold, we keep only the nodes with 10 times the mean Gt = G.copy() for k, v in ranking: if v &lt; t: Gt.remove_node(k) return GtGt = most_important(G) # trimming# draw the nodes and the edges (all)nx.draw_networkx_nodes(G,spring_pos,node_color='b',alpha=0.2,node_size=8)nx.draw_networkx_edges(G,spring_pos,alpha=0.1)# draw the most important nodes with a different stylenx.draw_networkx_nodes(Gt,spring_pos,node_color='r',alpha=0.4,node_size=254)# also the labels this timenx.draw_networkx_labels(Gt,spring_pos,font_size=6,font_color='b')plt.savefig(\"../output/FB_BetCen.png\", dpi = 300) 4. 社区发现（Community detection）import networkx as nximport matplotlib.pyplot as pltimport communityimport pandas as pdimport sys# Exploratory Data Analysis# datadf = pd.read_csv(sys.argv[1])#node1 = list(df[\"node1\"])G = nx.from_pandas_dataframe(df, 'node1', 'node2', #edge_attr='weight', #create_using=nx.MultiGraph() )#Quick snapshot of the Networkprint nx.info(G)#Create network layout for visualizationsspring_pos = nx.spring_layout(G)plt.axis(\"off\")#part = community.best_partition(G)values = [part.get(node) for node in G.nodes()]nx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)plt.savefig(\"../output/FB_commu.png\", dpi = 300)# get modularitymod = community.modularity(part,G)print(\"modularity:\", mod) 也可以在betweenness centrality的基础上画community detection: import networkx as nximport matplotlib.pyplot as pltimport communityimport pandas as pdimport sys# Exploratory Data Analysis# datadf = pd.read_csv(sys.argv[1])#node1 = list(df[\"node1\"])G = nx.from_pandas_dataframe(df, 'node1', 'node2', #edge_attr='weight', #create_using=nx.MultiGraph() )#Quick snapshot of the Networkprint nx.info(G)#Create network layout for visualizationsspring_pos = nx.spring_layout(G)plt.axis(\"off\")def most_important(G): \"\"\" returns a copy of G with the most important nodes according to the pagerank \"\"\" ranking = nx.betweenness_centrality(G).items() #print ranking r = [x[1] for x in ranking] m = sum(r)/len(r) # mean centrality t = m*10 # threshold, we keep only the nodes with 10 times the mean Gt = G.copy() for k, v in ranking: if v &lt; t: Gt.remove_node(k) return GtGt = most_important(G) # trimming# draw the nodes and the edges (all)nx.draw_networkx_nodes(G,spring_pos,node_color='b',alpha=0.2,node_size=8)nx.draw_networkx_edges(G,spring_pos,alpha=0.1)# draw the most important nodes with a different stylenx.draw_networkx_nodes(Gt,spring_pos,node_color='r',alpha=0.4,node_size=254)# also the labels this timenx.draw_networkx_labels(Gt,spring_pos,font_size=6,font_color='b')#part = community.best_partition(G)values = [part.get(node) for node in G.nodes()]nx.draw_networkx(G, pos = spring_pos, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)plt.savefig(\"../output/FB_BC_commu.png\", dpi = 300)# get modularitymod = community.modularity(part,G)print(\"modularity:\", mod)","categories":[{"name":"notes","slug":"notes","permalink":"https://hui-liu.github.io/categories/notes/"}],"tags":[{"name":"python","slug":"python","permalink":"https://hui-liu.github.io/tags/python/"}]},{"title":"如何在遍历时，正确删除列表中的 items","slug":"如何在遍历时，正确删除列表中的-items","date":"2017-03-08T09:21:23.000Z","updated":"2017-03-08T09:22:48.197Z","comments":true,"path":"2017-03-08-如何在遍历时，正确删除列表中的-items.html","link":"","permalink":"https://hui-liu.github.io/2017-03-08-如何在遍历时，正确删除列表中的-items.html","excerpt":"","text":"错误的代码x = ['a', 'b', 'c', 'd']y = ['b', 'c']for i in x: if i in y: x.remove(i)print x-----------------['a', 'c', 'd'] 正确的代码x = ['a', 'b', 'c', 'd']y = ['b', 'c']for i in x[:]: if i in y: x.remove(i)print x-----------------['a', 'd'] 实际上，id(x)与id(x[:])是不同的，所以只有在x的副本（x[:]）中遍历，然后在x中删除，才不会造成错误。","categories":[{"name":"code","slug":"code","permalink":"https://hui-liu.github.io/categories/code/"}],"tags":[{"name":"python","slug":"python","permalink":"https://hui-liu.github.io/tags/python/"}]},{"title":"根据一个list文件生成一个组合","slug":"根据一个list文件生成一个组合","date":"2017-03-05T08:35:07.000Z","updated":"2017-03-05T08:50:52.091Z","comments":true,"path":"2017-03-05-根据一个list文件生成一个组合.html","link":"","permalink":"https://hui-liu.github.io/2017-03-05-根据一个list文件生成一个组合.html","excerpt":"","text":"假设有一个 list 如下： $ cat aaabcd 期望生成如下组合： a ba ca db cb dc d 实现方法如下： #!/bin/bashset -- $(cat $1) # 将输入文件的每一行依次赋值给位置变量，如第一行赋值给 $1，第二行给 $2。。。for i in $* # $* 为所有位置变量的 listdoshift for j in $* do printf \"%s\\t%s\\n\" \"$i\" \"$j\" donedone $ ./pair_combination.sh aaa ba ca db cb dc d","categories":[{"name":"linux","slug":"linux","permalink":"https://hui-liu.github.io/categories/linux/"}],"tags":[{"name":"linux shell","slug":"linux-shell","permalink":"https://hui-liu.github.io/tags/linux-shell/"}]},{"title":"Detecting pervasive positive selection step by step","slug":"Detecting-pervasive-positive-selection","date":"2017-03-02T09:01:33.000Z","updated":"2017-03-03T14:03:45.599Z","comments":true,"path":"2017-03-02-Detecting-pervasive-positive-selection.html","link":"","permalink":"https://hui-liu.github.io/2017-03-02-Detecting-pervasive-positive-selection.html","excerpt":"","text":"Site-model: assumsing that the dn/ds rato is the same across branches, but different between sites(1) multiple sequence alignment speed: muscle &gt; mafft &gt; clustalW &gt; T-Coffee accuracy: mafft &gt; muscle &gt; T-Coffee &gt; clustalW cd /home/liuhui/nature_selection/exemple/data_for_codemlmafft-linsi ../input/HLA_DQB1.aa.fasta &gt; HLA_DQB1.aa.mafft.fasta (2) convert protein alignment to cds alignmentperl /home/liuhui/nature_selection/exemple/bin/pepMfa_to_cdsMfa.pl HLA_DQB1.aa.mafft.fasta ../input/HLA_DQB1.cds.fasta &gt; HLA_DQB1.cds.mafft.fasta (3) Remove spurious sequences and columns aa sequences (construct gene tree) trimal -automated1 -in HLA_DQB1.aa.mafft.fasta -out HLA_DQB1.aa.mafft.trimal.fasta -htmlout HLA_DQB1.aa.mafft.trimal.html -colnumbering &gt; HLA_DQB1.aa.mafft.trimal.cols cds sequences (for codeml) python /home/liuhui/nature_selection/bin/MSA_triplets_gaps_removed.py HLA_DQB1.cds.mafft.fasta HLA_DQB1.cds.mafft_removed_trigaps.fasta (4) convert fasta to phylip format/home/liuhui/nature_selection/exemple/bin/convert_fasta2phylip.py HLA_DQB1.aa.mafft.trimal.fasta HLA_DQB1.aa.mafft.trimal.phy # construct tree/home/liuhui/nature_selection/exemple/bin/convert_fasta2phylip.py HLA_DQB1.cds.mafft_removed_trigaps.fasta HLA_DQB1.cds.mafft_removed_trigaps.phy # for codeml (5) construct treephyml -i HLA_DQB1.aa.mafft.trimal.phy -q -d aa -m JTT -c 4 -a esed 's/\\()\\)[0-9]\\.[^:]*:/\\1:/g' HLA_DQB1.aa.mafft.trimal.phy_phyml_tree.txt &gt; HLA_DQB1.aa.mafft.trimal.tree (6) codeml# M0M1M2M3M7M8cd /home/liuhui/nature_selection/exemple/output/mkdir HLA_DQB1_M0M1M2M3M7M8cd HLA_DQB1_M0M1M2M3M7M8codeml HLA_DQB1_M0M1M2M3M7M8.ctl# M8acd /home/liuhui/nature_selection/exemple/output/mkdir HLA_DQB1_M8acd HLA_DQB1_M8acodeml HLA_DQB1_M8a.ctl (7) significant test np: the number of parameters lnL: log-likelihood value LRT: likelihood-ratio test Model_compared Model0 np0 lnL0 Model1 np1 lnL1 df LRT pvalueM7-M8 M7 44 -5047.785978 M8 46 -5011.936805 2 71.6983 2.69719269066922e-16M0-M3 M0 43 -5214.976615 M3 47 -5011.542624 4 406.868 9.12618975872726e-87M8-M8a M8a 45 -5031.655392 M8 46 -5011.936805 1 39.4372 3.38781154892534e-10M1a-M2a M1a 44 -5036.170805 M2a 46 -5014.302814 2 43.736 3.18308524710324e-10 (8) identification of sitesM2a Bayes Empirical Bayes (BEB) analysis (Yang, Wong &amp; Nielsen 2005. Mol. Biol. Evol. 22:1107-1118)Positively selected sites (: P&gt;95%; *: P&gt;99%)(amino acids refer to 1st sequence: ENSP00000364080) Pr(w&gt;1) post mean +- SE for w 38 F 0.938 3.258 +- 0.761 55 L 0.999** 3.408 +- 0.518 66 Y 0.837 2.994 +- 0.991 86 D 0.997** 3.404 +- 0.527 99 G 0.978* 3.356 +- 0.615 99 G 0.978* 3.356 +- 0.615116 F 0.935 3.243 +- 0.766118 G 0.662 2.542 +- 1.171123 R 0.690 2.646 +- 1.182256 P 0.998** 3.406 +- 0.523257 Q 0.864 3.073 +- 0.947258 G 0.968* 3.334 +- 0.659259 P 0.776 2.838 +- 1.079260 P 0.971* 3.342 +- 0.644 M8 Bayes Empirical Bayes (BEB) analysis (Yang, Wong &amp; Nielsen 2005. Mol. Biol. Evol. 22:1107-1118)Positively selected sites (: P&gt;95%; *: P&gt;99%)(amino acids refer to 1st sequence: ENSP00000364080) Pr(w&gt;1) post mean +- SE for w 14 T 0.539 1.770 +- 1.006 38 F 0.985* 2.688 +- 0.473 42 G 0.649 1.992 +- 0.956 55 L 1.000** 2.715 +- 0.417 66 Y 0.962* 2.641 +- 0.547 86 D 0.999** 2.714 +- 0.419 99 G 0.996** 2.709 +- 0.431113 E 0.518 1.714 +- 0.948116 F 0.989* 2.694 +- 0.459117 R 0.585 1.855 +- 0.957118 G 0.927 2.564 +- 0.632123 R 0.837 2.393 +- 0.822256 P 1.000** 2.715 +- 0.418257 Q 0.956* 2.630 +- 0.569258 G 0.992** 2.700 +- 0.451259 P 0.947 2.609 +- 0.588260 P 0.993** 2.703 +- 0.443","categories":[{"name":"Evolution","slug":"Evolution","permalink":"https://hui-liu.github.io/categories/Evolution/"}],"tags":[{"name":"positive selection","slug":"positive-selection","permalink":"https://hui-liu.github.io/tags/positive-selection/"}]},{"title":"creat a blog","slug":"creat a blog","date":"2017-03-02T05:01:44.000Z","updated":"2017-03-02T14:35:25.913Z","comments":true,"path":"2017-03-02-creat a blog.html","link":"","permalink":"https://hui-liu.github.io/2017-03-02-creat a blog.html","excerpt":"","text":"1. hexo new \"new blog title\"2. edit your text using Typora3. hexo generate4. hexo deploy","categories":[{"name":"blog","slug":"blog","permalink":"https://hui-liu.github.io/categories/blog/"}],"tags":[{"name":"notes","slug":"notes","permalink":"https://hui-liu.github.io/tags/notes/"}]}]}